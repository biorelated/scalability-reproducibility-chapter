Nextflow is a workflow manager and job orchestrator built on the data flow paradigm [1]. It is written in Groovy and leverages a very powerful and concise domain specific language (DSL) to describe processes and channels. The formers are where task execution is defined, the latters are the way in which inputs and outputs are passed from one process to the others during a workflow progression. 
In the DSL many commands and methods are available for common use cases in bioinformatics including, for instance, sequences file splitting, files searching and grouping by name, along with standard operators to allow manipulations on lists and collections. 
Nextflow is also very flexible allowing tasks itselves to be defined in multiple languages, including Bash, Python, Ruby, Groovy and others.
Nextflow and the data flow paradigm are based on a "push" concept, the first process in the workflow will send his outputs over to the following processes that will wait for the data to arrive before starting their computation. Branches in the workflow are also entirely possible and easy to define using conditions that specify if certain processes must be executed or not depending on the data or on user defined parameters. 
It is the closest representation of a pipeline idea, where you open the valve at the beginning and watch the flow progressing through the pipes. But Nextflow can handle this data flow in a parallel and asynchronous manner, so a process can operate on multiple inputs and emit multiple outputs at the same time. In a simple workflow where, for instance, there are 100 nucleotide sequences to be aligned with the NCBI NT database using Blast, a first process can compute the alignment on the 100 sequences in parallel, while a second process will wait to receive and collect each of the outputs from the 100 alignments to create a final results file. Nextflow can run a workflow locally or using a computing cluster, in that case common schedulers like SLURM, PBS, LSF and SGE are supported, plus a built-in scheduler is also available based on Apache Ignite. Nextflow allows also to run workflows directly into the Amazon Web Services (AWS) cloud using managed services like AWS Batch or automating the creation of a computing cluster in the cloud for the user.
In order to run the Nextflow example you need to have at least Java 8 available on your system and Docker, then to install Nextflow it is sufficient to run these commands:

cd $HOME 
curl -s https://get.nextflow.io | bash

Once Nextflow is installed, to run the example:

cd scalability-reproducibility-chapter/Nextflow
~/nextflow run workflow.nf -with-docker springer/scalability


